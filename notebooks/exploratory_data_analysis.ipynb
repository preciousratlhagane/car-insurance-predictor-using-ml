{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> üîç Exploratory Data Analysis </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"cont\"></a>\n",
    "\n",
    "## üìë Table of Contents\n",
    "\n",
    "<a href=\"#one\">1. Introduction\n",
    "   - Project Overview\n",
    "\n",
    "<a href=#two>2. Loading Data\n",
    "   - Importing libraries\n",
    "   - Reading the dataset\n",
    "\n",
    "<a href=#three>3. Exploratory Data Analysis (EDA)</a>\n",
    "\n",
    "<a href=#five>4. Feature Engineering</a>\n",
    "\n",
    "<a href=#six>5. Modeling</a>\n",
    "\n",
    "<a href=#seven>6. Model Performance</a>\n",
    "\n",
    "<a href=#eight>7. Model Explanations</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"one\"></a>\n",
    "## 1. Introduction\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "\n",
    "---\n",
    "    \n",
    "| ‚ö° Description: Introducing the project ‚ö° |\n",
    "| :--------------------------- |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Project Overview*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Objective\n",
    "\n",
    "The aim of this project is to develop a machine learning model that predicts car insurance premiums based on customer demographics. \n",
    "\n",
    "#### Context/Background\n",
    "\n",
    "Accurate premium predictions ensures transparency and fairness in cost assessment for customers \n",
    "\n",
    "#### Dataset Overview\n",
    "\n",
    "| **Source**       | **Description**                          |\n",
    "|------------------|-------------------------------------------|\n",
    "| `data/train.csv`  | Training data with target premiums        |\n",
    "| `data/test.csv`   | Test data for final predictions           |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"two\"></a>\n",
    "## üìÇ 2. Loading Data\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ‚ö° Description: Loading the data in our environment ‚ö° |\n",
    "| :--------------------------- |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìö *Importing libraries*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the packages \n",
    "import warnings\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìñ *Reading the dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/car_insurance_premiums_zar.csv\")\n",
    "\n",
    "\n",
    "#Display the first few rows of the datasets and their shape\n",
    "display(\"Dataset\", data.head(), data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get a concise summmary of the data dataset\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"three\"></a>\n",
    "## 3. üîç Exploratory Data Analysis (EDA)\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ‚ö° Description: Exploring the data ‚ö° |\n",
    "| :--------------------------- |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for duplicates in the data set\n",
    "train_duplicates = data[data.duplicated()]\n",
    "num_duplicates = len(train_duplicates)\n",
    "print(f\"There are {num_duplicates} duplicates in the data dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for the distribution of each categorical feature\n",
    "categorical_columns = data.select_dtypes(include=[\"object\"]).columns\n",
    "for col in categorical_columns:\n",
    "    print(f\"\\nDistribution for {col}\")\n",
    "    print(data[col].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The demographic factors in our dataset are fairly balanced with no significant overrepresentation or underrepresentation of any group meaning that these factors should not introduce any bias into the model training. \n",
    "\n",
    "* Vehicle details are also fairly balanced which is ideal for our predictive modelling task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Quality Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Education Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determine the unique values that are in the \"Education\" column\n",
    "data[\"Education_Level\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define minimum age requirements for each education level\n",
    "education_age_limits = {\n",
    "    \"High School\": 18,\n",
    "    \"Higher Certificate\": 18,\n",
    "    \"Bachelor's Degree\": 18,      \n",
    "    \"Master's Degree\": 22,                  \n",
    "    \"Doctorate\": 24      \n",
    "}\n",
    "\n",
    "# Flag invalid rows where age is too low for the education level\n",
    "invalid_education_rows = data[data.apply(lambda row: row[\"Age\"] < education_age_limits.get(\n",
    "    row[\"Education_Level\"], 0), axis=1)]\n",
    "\n",
    "# Display errors\n",
    "print(invalid_education_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a boolean mask for invalid rows where True = Invalid and False = Valid\n",
    "hue_values = data.index.isin(invalid_education_rows.index)\n",
    "\n",
    "# Define color palette explicitly as a dictionary\n",
    "palette = {True: \"red\", False: \"blue\"}\n",
    "\n",
    "# Plot strip plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "ax = sns.stripplot(x=data[\"Education_Level\"],\n",
    "                   y=data[\"Age\"],\n",
    "                   hue=hue_values,\n",
    "                   palette=palette,\n",
    "                   size=8, jitter=True)\n",
    "\n",
    "# Fix legend labels manually\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles, [\"Valid\", \"Invalid\"], title=\"Data Status\")\n",
    "\n",
    "plt.title(\"Age vs Education Level (Invalid Rows in Red)\")\n",
    "plt.xlabel(\"Education Level\")\n",
    "plt.ylabel(\"Age\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove invalid rows from the original DataFrame in place\n",
    "cleaned_data = data[data.apply(\n",
    "    lambda row: row[\"Age\"] >= education_age_limits.get(row[\"Education_Level\"], float('inf')), axis=1)]\n",
    "\n",
    "#Check the shape of the resulting dataset\n",
    "cleaned_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Employment status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the unique categories in the \"Employment_Status\" column\n",
    "cleaned_data[\"Employment_Status\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the invalid rows in the dataset according to the mimimum age required for an educational level\n",
    "employment_age_limits = {\n",
    "    \"Unemployed\": (18, 65),\n",
    "    \"Employed\": (18, 65), \n",
    "    \"Self-Employed\": (18, 80),\n",
    "    \"Retired\": (65, 100)\n",
    "}\n",
    "\n",
    "invalid_employment_status = cleaned_data[cleaned_data.apply(lambda row: not (employment_age_limits.get(row[\"Employment_Status\"], (0, 150))[0] <= row[\"Age\"] <= employment_age_limits.get(row[\"Employment_Status\"], (0, 150))[1]), axis = 1)]\n",
    "invalid_employment_status.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "# Ensure hue is a 1D Boolean Series\n",
    "hue_values = cleaned_data.index.isin(\n",
    "    invalid_employment_status.index)  # Boolean Series\n",
    "\n",
    "sns.stripplot(x=cleaned_data[\"Employment_Status\"],\n",
    "              y=cleaned_data[\"Age\"],\n",
    "              hue=hue_values,  # Fix here\n",
    "              palette={True: \"red\", False: \"blue\"},\n",
    "              size=8, jitter=True)\n",
    "\n",
    "plt.title(\"Age vs Employment Status (Invalid Rows in Red)\")\n",
    "plt.xlabel(\"Employment Status\")\n",
    "plt.ylabel(\"Age\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title=\"Invalid Data\", labels=[\"Valid\", \"Invalid\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above graph represents a stacked bar graph which highlights logically invalid data points in red and valid ones in blue.\n",
    " \n",
    " * There is a high number of red points between the ages of 18-55, which are ages that are too young to be considered retired.\n",
    " * There are red points in the \"Employed\" and 'Unemployed\" categories for the 65+ age group because it is uncommon to be employed beyond the age of 65.\n",
    " * Anyone beyond the age of 65+ would typically be considered \"Retired\" even if they have been unemployed their entire lives as they are too old to enter the workforce. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set target proportions from original distribution\n",
    "target_distribution = {\n",
    "    \"Retired\": 0.257376,\n",
    "    \"Employed\": 0.250567,\n",
    "    \"Unemployed\": 0.248917,\n",
    "    \"Self-Employed\": 0.243140\n",
    "}\n",
    "\n",
    "# Get total number of rows in cleaned_data\n",
    "total_rows = len(cleaned_data)\n",
    "\n",
    "# Count how many records we currently have\n",
    "current_counts = Counter(cleaned_data[\"Employment_Status\"])\n",
    "\n",
    "\n",
    "def fix_employment_smart(row):\n",
    "    age = row[\"Age\"]\n",
    "    current_status = row[\"Employment_Status\"]\n",
    "\n",
    "    # Is the age valid for this status?\n",
    "    min_age, max_age = employment_age_limits.get(current_status, (0, 150))\n",
    "    if min_age <= age <= max_age:\n",
    "        return current_status  # No fix needed\n",
    "\n",
    "    # Find all valid statuses for this age\n",
    "    valid_statuses = [\n",
    "        status for status, (min_a, max_a) in employment_age_limits.items()\n",
    "        if min_a <= age <= max_a\n",
    "    ]\n",
    "\n",
    "    if not valid_statuses:\n",
    "        return current_status  # fallback\n",
    "\n",
    "    # Prefer status that brings us closer to original proportions\n",
    "    best_status = None\n",
    "    smallest_gap = float(\"inf\")\n",
    "\n",
    "    for status in valid_statuses:\n",
    "        current_prop = current_counts[status] / total_rows\n",
    "        target_prop = target_distribution.get(status, 0)\n",
    "        gap = abs(target_prop - current_prop)\n",
    "        if gap < smallest_gap:\n",
    "            smallest_gap = gap\n",
    "            best_status = status\n",
    "\n",
    "    # Update the count to reflect the new assignment\n",
    "    current_counts[best_status] += 1\n",
    "\n",
    "    return best_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply the function to fix the logical inconsistencies in the \"Employment_Status\" column\n",
    "cleaned_data[\"Employment_Status\"] = cleaned_data.apply(fix_employment_smart, axis=1)\n",
    "\n",
    "# Check final distribution\n",
    "print(cleaned_data[\"Employment_Status\"].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform a test to validate that the above function worked\n",
    "invalid_employment_status = cleaned_data[cleaned_data.apply(lambda row: not (employment_age_limits.get(row[\"Employment_Status\"], (0, 150))[\n",
    "                                              0] <= row[\"Age\"] <= employment_age_limits.get(row[\"Employment_Status\"], (0, 150))[1]), axis=1)]\n",
    "if invalid_employment_status.empty:\n",
    "    print(\"All employment statuses are valid based on the age ranges\")\n",
    "else:\n",
    "    print(\n",
    "        f\"‚ùå Found {len(invalid_employment_status)} invalid rows where employment status does not match the age.\")\n",
    "    display(invalid_employment_status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of years driving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The `Years_Driving` column represents the number of years that a person has been driving. \n",
    "* Logically, the values in this column can't be larger than the person's age minus 18 as the minimum age to obtain a full driving licence is 18 in South Africa. \n",
    "* We will proceed to identify rows in the `Years_Driving` column that are logically inaccurate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify rows where years_driving is greater than (age - 18)\n",
    "invalid_years_driving_rows = cleaned_data[cleaned_data[\"Years_Driving\"] > (\n",
    "    cleaned_data[\"Age\"] - 18)]\n",
    "print(invalid_years_driving_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* There are 4573 logically inconsistent rows which account for nearly half of the total rows in the dataset so removing these rows will lead to significant loss of data. \n",
    "* We will use a bar graph to visualize the distribution of the logical inconsistencies across various age groups. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define age bins\n",
    "bins = [18, 25, 35, 45, 55, 65, 75, 100]  # Adjust as needed\n",
    "labels = [\"18-25\", \"26-35\", \"36-45\", \"46-55\",\n",
    "          \"56-65\", \"66-75\", \"76+\"]  # Labels for bins\n",
    "\n",
    "# Create a new column for age groups\n",
    "invalid_years_driving_rows[\"Age_Group\"] = pd.cut(\n",
    "    invalid_years_driving_rows[\"Age\"], bins=bins, labels=labels, right=True)\n",
    "\n",
    "# Count invalid cases per age group\n",
    "invalid_counts_grouped = invalid_years_driving_rows[\"Age_Group\"].value_counts(\n",
    ").sort_index()\n",
    "\n",
    "# Plot bar chart\n",
    "plt.figure(figsize=(10, 5))\n",
    "ax = sns.barplot(x=invalid_counts_grouped.index,\n",
    "                 y=invalid_counts_grouped.values, color=\"red\")\n",
    "\n",
    "# Add numbers on top of bars (convert to integer)\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f'{int(p.get_height())}',  # Convert to integer\n",
    "                (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                ha='center', va='center',\n",
    "                fontsize=12, color='black',\n",
    "                xytext=(0, 5), textcoords='offset points')\n",
    "\n",
    "plt.title(\"Count of Invalid Years Driving by Age Group\")\n",
    "plt.xlabel(\"Age Group\")\n",
    "plt.ylabel(\"Number of Invalid Entries\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The `18-45` age groups have the top 3 highest logical inconsistencies.  \n",
    "\n",
    "* We can set the `Years_Driving` to be equal to `Age - 18` if it exceeds that value. \n",
    "* This ensures that we do not lose any valuable data while keeping the data consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace any logical inconsistent rows to be within valid range\n",
    "cleaned_data.loc[cleaned_data[\"Years_Driving\"] > (cleaned_data[\"Age\"] - 18), \"Years_Driving\"] = cleaned_data[\"Age\"] - 18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We will now perform a test to determine that all the logical inconsistencies have been fixed by the above function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check whether the Years_Driving column is now within the valid range\n",
    "invalid_years_driving_rows = cleaned_data[cleaned_data[\"Years_Driving\"] > (\n",
    "    cleaned_data[\"Age\"] - 18)]\n",
    "print(invalid_education_rows)\n",
    "\n",
    "# Display a summary sentence\n",
    "if invalid_years_driving_rows.empty:\n",
    "    print(\"‚úÖ All employment statuses are valid based on the age ranges.\")\n",
    "else:\n",
    "    print(\n",
    "        f\"‚ùå Found {len(invalid_years_driving_rows)} invalid rows where employment status does not match the age.\")\n",
    "    display(invalid_years_driving_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Median insurance premium amount per annum by car details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'Car_Model', 'Car_Make', 'Manufacture_Year' and calculate the median of 'Premium_Amount'\n",
    "median_model_premiums = cleaned_data.groupby(\n",
    "    [\"Car_Model\", \"Car_Make\", \"Manufacture_Year\"])[\"Premium_Amount\"].median().reset_index()\n",
    "\n",
    "# Create a new column that combines Car_Model, Car_Make, and Manufacture_Year\n",
    "median_model_premiums['Car_Description'] = (median_model_premiums['Car_Model'] + \" \" +\n",
    "                                            median_model_premiums['Car_Make'] + \" (\" +\n",
    "                                            median_model_premiums['Manufacture_Year'].astype(str) + \")\")\n",
    "\n",
    "# Sort by 'Premium_Amount' in descending order and select top 5\n",
    "top_5_models = median_model_premiums.sort_values(\n",
    "    by=\"Premium_Amount\", ascending=False).head(5)\n",
    "\n",
    "# Create the bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = sns.barplot(y=\"Car_Description\", x=\"Premium_Amount\",\n",
    "                 data=top_5_models, palette=\"bright\")\n",
    "\n",
    "# Add value labels on top of the bars\n",
    "for index, value in enumerate(top_5_models[\"Premium_Amount\"]):\n",
    "    plt.text(value, index, f'{value:,.0f}', va=\"center\", fontsize=10)\n",
    "\n",
    "plt.ylabel(\"Car Description (Model, Make, Year)\")\n",
    "plt.xlabel(\"Median Premium Amount per annum\")\n",
    "plt.title(\"Median Insurance Premium per annum by Car Model, Make, and Year\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The horizontal bar graph displays the top 5 cars with the highest median insurance premium per annum using model, make and year.\n",
    "\n",
    "* The **Hyundai Tucson(1999)** has the highest median annual premium at **R83,295**. \n",
    "    * Older cars sometimes have higher premiums due to expensive parts which may not be readily avaliable or increased risk factors.\n",
    "\n",
    "* The **Hyundai Elantra(2012)** has the lowest among the top five, at **R77,256**.\n",
    "    * This can be as a result of better safety features, lower theft rates, or lower repair costs compared to others. \n",
    "\n",
    "* The **Kia Forte(2022)** has a high premium(**R83,892**) despite being the newest while the **Civic(1998)** and **CR-V(2002)** also have similar premiums. \n",
    "    * This suggests that other factors such as claim history, accident history play a role beyond car age. \n",
    "\n",
    "The median premiums are relatively close, implying that factors beyond car type might have a stronger impact. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distribution of insurance claims by the number of accidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(x=\"Number_of_Accidents\", y=\"Number_of_Claims\",\n",
    "            data=cleaned_data, palette=\"pastel\")\n",
    "plt.xlabel(\"Number of Accidents\")\n",
    "plt.ylabel(\"Number of Claims\")\n",
    "plt.title(\"Distribution of Claims by Number of Accidents\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above visual is a box plots showing the distribution of the number of claims across different number of accident categories. \n",
    "\n",
    "* The number of claims does not increase linearly with the number of accidents - which is unexpcted for an insurance dataset. \n",
    "* This means that other factors such as policy term, years driving may influence clam numbers more than accident count.\n",
    "* This also suggests that claims may not be strongly correlated with the number of accidents, or at least not in a simple, direct way. \n",
    "* Claims can include other incidents besides accidents.\n",
    "* This could be an indication of potential fraudelent claims, unrreporting of accidents or policyholders have multiple claims from a single accident. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Median premium amount per annum by the number of accidents and claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_data = cleaned_data.pivot_table(\n",
    "    index=\"Number_of_Claims\",\n",
    "    columns=\"Number_of_Accidents\",\n",
    "    values=\"Premium_Amount\",\n",
    "    aggfunc=\"median\"\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(heatmap_data, cmap=\"coolwarm\", annot=True, fmt=\".0f\", linewidths=0.5, cbar_kws={\"label\": \"Median Premium Amount per annum\"})\n",
    "\n",
    "plt.xlabel(\"Number of Accidents\")\n",
    "plt.ylabel(\"Number of Claims\")\n",
    "plt.title(\"Median Premium Amount per annum by Number of Accidents and Claims\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The heatmap above displays the median premium amount per annum according to *claim history* and *accident history*. \n",
    "\n",
    "* There is no postive linear relationship between the claim history and the accident history which is surprising as one is expected to pay more premiums as the number of claims increase because your risk profile also increases. \n",
    "* The highest premium per annum (**R57,996**) has had only one accident and three claims which could be a result of claims from other incidents such as stolen vehicle parts, a weather-related claim or a glass-replacement claim.\n",
    "* The second highest premium per annum(**R57,681**) has had only six claims and two accidents which are higher than the indivdual with the highest premium.\n",
    "    * This suggests that other factors may play a bigger role in determining the final insurance premium. \n",
    "* The lowest premium per annum (**R44,334**) is from an individual with four accidents and nine claims which is surprising. This can due to a number of reasons: \n",
    "    * Long term discounts based on customer loyalty or multiple policies by the same insurer\n",
    "    * Low-risk driver profile based on demographic factors\n",
    "    * The claim types are not-at-fault\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Medium premium amount per annum by years_of_driving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize the median premium per annum based on the number of years drivibg \n",
    "median_years_premiums = cleaned_data.groupby(\"Years_Driving\")[\"Premium_Amount\"].median().reset_index()\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.lineplot(x=\"Years_Driving\", y=\"Premium_Amount\", data=median_years_premiums, color=\"b\")\n",
    "plt.xlabel(\"Years of Driving\")\n",
    "plt.ylabel(\"Median Premium Amount per annum\")\n",
    "plt.title(\"Median Amount by Years of Driving\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above line graph displays the median premium amount per annum by years of driving.\n",
    "\n",
    "* The higest premium amount is from an individual with 20 years of driving experience.\n",
    "* The lowest premium amount is from an individual with 60 years driving experience. \n",
    "* There are varying lengths of premiums amounts as the years of driving increase which could be to a number of reasons:\n",
    "    * Non-linear risk patterns\n",
    "    * Claim history vs driving experience\n",
    "    * Differences in policy terms\n",
    "    * Insurance company pricing as a result of age, loyalty discounts or market changes. \n",
    "\n",
    "There is typically no linear relationship between the two variables indicating that there might be various other factors which have an impact on the final premium amount."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Credit score range vs Median premium amount per annum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort the credit scores into categories \n",
    "def categorize_credit_score(credit_score):\n",
    "    if credit_score < 580:\n",
    "        return \"Poor\"\n",
    "    elif 580 <= credit_score < 670:\n",
    "        return \"Fair\"\n",
    "    elif 670 <= credit_score < 740:\n",
    "        return \"Good\"\n",
    "    elif 740 <= credit_score < 800:\n",
    "        return \"Very Good\"\n",
    "    else:\n",
    "        return \"Excellent\"\n",
    "\n",
    "\n",
    "#Apply the function to the main dataset\n",
    "cleaned_data[\"Credit_Category\"] = cleaned_data[\"Credit_Score\"].apply(\n",
    "    categorize_credit_score)\n",
    "\n",
    "#Calculate median premiums for each category\n",
    "median_premium = cleaned_data.groupby(\"Credit_Category\")[\n",
    "    \"Premium_Amount\"].median().sort_values(ascending=False)\n",
    "\n",
    "#Reorder categories in the dataset based on sorted order\n",
    "sorted_categories = median_premium.index.tolist()\n",
    "cleaned_data[\"Credit_Category\"] = pd.Categorical(\n",
    "    cleaned_data[\"Credit_Category\"],\n",
    "    categories=sorted_categories,\n",
    "    ordered=True\n",
    ")\n",
    "\n",
    "#Plot using original cleaned_data but sorted categories\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(\n",
    "    data=cleaned_data,\n",
    "    y=\"Credit_Category\",\n",
    "    x=\"Premium_Amount\",\n",
    "    estimator=\"median\",\n",
    "    order=sorted_categories,\n",
    "    palette=\"coolwarm\",\n",
    "    ci=None\n",
    ")\n",
    "\n",
    "#Add labels to the horizontal bars\n",
    "for i, (cat, val) in enumerate(median_premium.items()):\n",
    "    plt.text(val + 20, i, f\"{int(val)}\", va=\"center\", fontsize=12)\n",
    "\n",
    "plt.title(\"Median Premium by Credit Score Category\")\n",
    "plt.ylabel(\"Credit Score Category\")\n",
    "plt.xlabel(\"Median Premium (ZAR)\")\n",
    "plt.xlim(0, median_premium.max() + 100)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above graph is a horizontal bar graph that represents the median premium amount across six different credit score categories. \n",
    "\n",
    "* The results are surprising as one would usually expect the following: \n",
    "    * Higher credit score would lead to lower premiums, because insurers usually consiser good credit as a sign of lower risk. \n",
    "    * The *Excellent* and *Very Good* credit score categories have the same highest premiums while *Poor* and *Good* have the lowest premiums. \n",
    "* Possible explanations for the above observations could be: \n",
    "    * Other features dominate risk assessment\n",
    "    * Correlation with other features - e.g people with excellent credit might be insuring more expensive cars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Median premium amount per annum vs anti-theft device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by Anti-Theft Device status and calculate median premium\n",
    "median_premium_anti_theft = cleaned_data.groupby(\"Has_AntiTheft_Device\")[\n",
    "    \"Premium_Amount\"].median().reset_index()\n",
    "\n",
    "# Sort in descending order (optional)\n",
    "median_premium_anti_theft = median_premium_anti_theft.sort_values(\n",
    "    \"Premium_Amount\", ascending=False)\n",
    "\n",
    "# Convert the column to categorical for proper ordering\n",
    "median_premium_anti_theft[\"Has_AntiTheft_Device\"] = median_premium_anti_theft[\"Has_AntiTheft_Device\"].map({\n",
    "                                                                                                    1: \"Yes\", 0: \"No\"})\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "# Create horizontal bar chart\n",
    "sns.barplot(y=\"Has_AntiTheft_Device\", x=\"Premium_Amount\",\n",
    "            data=median_premium_anti_theft, palette=\"coolwarm\")\n",
    "\n",
    "# Add labels with thousands separator\n",
    "for index, row in median_premium_anti_theft.iterrows():\n",
    "    plt.text(row.Premium_Amount + 50, index,  # Offset label for readability\n",
    "             f\"{row.Premium_Amount:,.0f}\",  # Format numbers with commas\n",
    "             ha=\"left\", va=\"center\", fontsize=12, color=\"black\")\n",
    "\n",
    "plt.title(\"Median Premium Amount: Anti-Theft Device vs No Device\", fontsize=14)\n",
    "plt.ylabel(\"Anti-Theft Device Installed?\", fontsize=12)\n",
    "plt.xlabel(\"Median Premium (ZAR)\", fontsize=12)\n",
    "\n",
    "# Adjust x-axis limits for better spacing\n",
    "plt.xlim(0, median_premium_anti_theft[\"Premium_Amount\"].max() + 500)\n",
    "\n",
    "# Light grid lines for readability\n",
    "plt.grid(axis=\"x\", linestyle=\"--\", alpha=0.6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above graph is a categorical bar graph that displays the median premium per annum of individuals who have anti-theft device vs. those without it. \n",
    "* The median premiums are very similar which suggests that other features play a more significant role in determining the premium.\n",
    "* Typically, having an anti-theft device lowers your risk profile as it improves vehicle security, aids in recovery when stolen thus potentially reducing insurance costs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_train_columns = cleaned_data.select_dtypes(include=[np.number])\n",
    "correlation_matrix = numeric_train_columns.corr()\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\", cbar=True, linewidths=0.5)\n",
    "plt.title(\"Correlation Heatmap of Numeric Features\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above visual represents the correlation heatmap of the numeric features in our dataset.\n",
    "* There is a positive moderate correlation between the age and the years_driving feature. \n",
    "    * This means that as the age increases, the years_driving column also increases(or vice versa)\n",
    "    * This is due to the fact that the years_driving feature is dependent on age it measures the number of years an individual has been driving since they turned 18. \n",
    "* There is no correlation across all the other features indicating that there exists a non-linear relationship. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Five-number summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The five-number summary above provides a quick summary of the dataset. These include the minimum, first quartile, median, third quartile, and maximum. \n",
    "* This helps identify any potential outliners and gives insights into the data's central tendency and spread."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"four\"></a>\n",
    "## ‚öôÔ∏è 4. Feature Engineering\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ‚ö° Description: Transforming our data ‚ö° |\n",
    "| :--------------------------- |\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
